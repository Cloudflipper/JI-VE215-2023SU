{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cloudflipper/JI-VE215-2023SU-labRPT/blob/main/test12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su71ERu6scQb",
        "outputId": "5a2da175-2d14-4b5b-b6fd-9a62655f571d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6000, 8, 17)\n",
            "(5000, 8, 17)\n",
            "(1000, 8, 17)\n",
            "Epoch 40, Val Loss: 0.26327353095983635, Time cost:29.86997628211975s, Time remain: 7438.371378004551\n",
            "Epoch 80, Val Loss: 0.26243149852525194, Time cost:59.95578455924988s, Time remain: 7435.267117023468\n",
            "Epoch 120, Val Loss: 0.2610711196956776, Time cost:89.89136815071106s, Time remain: 7401.805268794298\n",
            "Epoch 160, Val Loss: 0.2612865522366017, Time cost:119.15510106086731s, Time remain: 7328.783551938832\n",
            "Epoch 200, Val Loss: 0.2615476920559036, Time cost:149.19363141059875s, Time remain: 7311.234024113416\n",
            "Epoch 240, Val Loss: 0.261734075242482, Time cost:179.02257680892944s, Time remain: 7280.997461873293\n",
            "Epoch 280, Val Loss: 0.2616394585502019, Time cost:209.2201623916626s, Time remain: 7263.6757838155545\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import math\n",
        "from numba import cuda\n",
        "import torch.nn as nn\n",
        "#import pycuda.driver as cuda\n",
        "\n",
        "def get_FEA_matrices(Fx_path, Fy_path, Fz_path):\n",
        "    Fx_all = pd.read_excel(Fx_path, usecols=range(0,8),  nrows=6875,  header=None)\n",
        "    Fy_all = pd.read_excel(Fy_path, usecols=range(0,8),  nrows=6875,  header=None)\n",
        "    Fz_all = pd.read_excel(Fz_path, usecols=range(0,8),  nrows=6875,  header=None)\n",
        "    # 将 DataFrame 转换为 NumPy 数组\n",
        "    Fx_all_v = Fx_all.values\n",
        "    # print(Fx_all_v.shape,Fx_all_v.ndim)\n",
        "    Fy_all_v = Fy_all.values\n",
        "    Fz_all_v = Fz_all.values\n",
        "\n",
        "    # for index, row in enumerate(Fx_all_v[:, [0,2,4,6]]):\n",
        "    #     #将离谱值替换为附近的值\n",
        "    #     if np.any(row > -0.25):\n",
        "    #         # print(f\"index={index}, row={row}\")\n",
        "    #         Fx_all_v[index,[0,2,4,6]] = Fx_all_v[index-1,[0,2,4,6]]\n",
        "\n",
        "    #选取需要的触点,Fz_R 取负值 F_FEA=[Fx1_R, Fx2_R, Fy_1_R, Fy2_R, Fz_1_R, Fz2_R, Fx1_L, Fx2_L, Fy_1_L, Fy2_L, Fz_1_L, Fz2_L]\n",
        "    F_FEA = np.concatenate((Fx_all_v[:, [4, 6]], Fy_all_v[:, [5, 7]], Fz_all_v[:, [4, 6]], \\\n",
        "                            Fx_all_v[:, [0, 2]], Fy_all_v[:, [1, 3]], -Fz_all_v[:, [0, 2]]), axis=1)\n",
        "    # print(F_FEA.shape)\n",
        "    return F_FEA\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        # Assuming data is a NumPy array of shape (2000, 3, 14)\n",
        "        print(data.shape)\n",
        "        self.inputs = data[:, :, 6:]  # Last 8 floats are forces\n",
        "        self.directions = data[:, :, 3:6]  # Directions are the 4th to 6th integers\n",
        "        self.locations = data[:, :, :3]  # Locations are the first 3 integers\n",
        "\n",
        "        # Normalize inputs\n",
        "        #self.inputs = (self.inputs - self.inputs.mean()) / self.inputs.std()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.inputs[idx], self.locations[idx], self.directions[idx]\n",
        "\n",
        "\n",
        "def Normalize_F(F_matrix):\n",
        "    for column in range(F_matrix.shape[1]):\n",
        "        # Fx, Fy, Fz Min-Max 归一化至 [-1,1]\n",
        "        F_matrix[:,column] = 2 * (F_matrix[:,column] - np.min(F_matrix[:,column])) / (np.max(F_matrix[:,column]) - np.min(F_matrix[:,column])) - 1\n",
        "\n",
        "    F_normalized_matrix = F_matrix\n",
        "    # print(f\"normalized F shape= {F_normalized_matrix.shape}\")\n",
        "    return F_normalized_matrix\n",
        "\n",
        "\n",
        "\n",
        "def change():\n",
        "    return np.random.uniform(-1,1)\n",
        "\n",
        "def tag_(disp):\n",
        "    def tag(num):\n",
        "        if num>2:\n",
        "            return 1\n",
        "        elif num<-2:\n",
        "            return -1\n",
        "        else:\n",
        "            return 0\n",
        "    disp.append(tag(disp[0]))\n",
        "    disp.append(tag(disp[1]))\n",
        "    disp.append(tag(disp[2]))\n",
        "\n",
        "def get_int_force(disp,FEA_DATA):\n",
        "    return FEA_DATA[round(275*disp[0]+11*disp[1]+disp[2]/3+3437)]\n",
        "\n",
        "def weight_force(digit,lower,upper):\n",
        "    digit = digit-math.floor(digit)\n",
        "    lower, upper = np.array(lower),np.array(upper)\n",
        "    return (lower*(1-digit)+upper*digit).tolist()\n",
        "\n",
        "def get_force(disp,FEA_DATA):\n",
        "    x_floor = math.floor(disp[0])\n",
        "    x_ceil = math.ceil(disp[0])\n",
        "    y_floor = math.floor(disp[1])\n",
        "    y_ceil = math.ceil(disp[1])\n",
        "    a_floor = math.floor(disp[2]/3)*3\n",
        "    a_ceil = math.ceil(disp[2]/3)*3\n",
        "    yfaf= weight_force(disp[0],get_int_force([x_floor,y_floor,a_floor],FEA_DATA),get_int_force([x_ceil,y_floor,a_floor],FEA_DATA))\n",
        "    ycaf= weight_force(disp[0],get_int_force([x_floor,y_ceil,a_floor],FEA_DATA),get_int_force([x_ceil,y_ceil,a_floor],FEA_DATA))\n",
        "    yfac= weight_force(disp[0],get_int_force([x_floor,y_floor,a_ceil],FEA_DATA),get_int_force([x_ceil,y_floor,a_ceil],FEA_DATA))\n",
        "    ycac= weight_force(disp[0],get_int_force([x_floor,y_ceil,a_ceil],FEA_DATA),get_int_force([x_ceil,y_ceil,a_ceil],FEA_DATA))\n",
        "    af = weight_force(disp[1],yfaf,ycaf)\n",
        "    ac = weight_force(disp[1],yfac,ycac)\n",
        "    return weight_force(disp[2],af,ac)\n",
        "\n",
        "def tag_force (disp,FEA_DATA):\n",
        "    rounded_list = np.array(get_force(disp,FEA_DATA))\n",
        "    rounded_list_without_y = rounded_list[:2].tolist()+ rounded_list[4:8].tolist()+ rounded_list[10:].tolist()\n",
        "    disp = disp + rounded_list_without_y\n",
        "    return disp\n",
        "\n",
        "def diff_data_(arr):\n",
        "    # Initialize the output array with zeros\n",
        "    transformed_arr = np.zeros((arr.shape[0]-1, 17))\n",
        "\n",
        "    # Calculate averages for the first 6 values\n",
        "    for j in range(6):\n",
        "        transformed_arr[:, j] = arr[1:, j]\n",
        "    for j in range(6,9):\n",
        "        transformed_arr[:,j] = arr[1:,j-6]-arr[:-1,j-6]\n",
        "    # Calculate differences for the last 8 values\n",
        "    for j in range(9, 17):\n",
        "        transformed_arr[:, j] = arr[1:, j] - arr[:-1, j]\n",
        "    return transformed_arr\n",
        "\n",
        "def data_make(FEA_DATA):\n",
        "    data = np.zeros([SAMPLE,STEP-1,17])\n",
        "    sum = 0\n",
        "\n",
        "    while sum<SAMPLE:\n",
        "        jump = False\n",
        "        steps = STEP\n",
        "        disp=[[np.random.uniform(-12,12),np.random.uniform(-12,12),np.random.uniform(-15,15)]]\n",
        "        tag_(disp[0])\n",
        "        disp[0]+=[0.,0.,0.]\n",
        "        disp[0]=tag_force(disp[0],FEA_DATA)\n",
        "        for index in range(steps-1):\n",
        "            disp.append([disp[index][0]+change(),disp[index][1]+change(),disp[index][2]+change()*3])\n",
        "            if (abs(disp[index+1][0])>12 or abs(disp[index+1][1])>12 or abs(disp[index+1][2])>15):\n",
        "                jump = True\n",
        "                continue\n",
        "            tag_(disp[index+1])\n",
        "            disp[index+1]+=[0.,0.,0.]\n",
        "            disp[index+1]=tag_force(disp[index+1],FEA_DATA)\n",
        "            #disp[index][0],disp[index][1],disp[index][2] = disp[index][0]/12,disp[index][1]/12,disp[index][2]/15\n",
        "        if (jump == True):\n",
        "            continue\n",
        "        for _ in range(STEP):\n",
        "            disp[_][0],disp[_][1],disp[_][2],disp[_][6],disp[_][7],disp[_][8] = disp[_][0]/12,disp[_][1]/12,disp[_][2]/15,disp[_][6]/12,disp[_][7]/12,disp[_][8]/15\n",
        "        original_data=(np.array(disp,dtype=float))\n",
        "        data[sum]= diff_data_(original_data)\n",
        "        #print(data[sum])\n",
        "        sum +=1\n",
        "    #print(data.shape)\n",
        "    return data\n",
        "# Mock data for demonstration\n",
        "\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=1, output_size=1, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers) # utilize the LSTM model in torch.nn\n",
        "        self.forwardCalculation = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, _x):\n",
        "        #print(_x.dtype)\n",
        "        x, _ = self.lstm(_x.float())  # _x is input, size (seq_len, batch, input_size)\n",
        "        s, b, h = x.shape  # x is output, size (seq_len, batch, hidden_size)\n",
        "        x = x.view(s*b, h)\n",
        "        x = self.forwardCalculation(x)\n",
        "        x = x.view(s, b, -1)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Assuming 8 features for input, hidden size of 170, and 3 outputs for directions\n",
        "\n",
        "\n",
        "#@jit(nopython=True)\n",
        "def train_model_direction(model, train_loader, val_loader, num_epochs=100):\n",
        "    output = np.zeros([num_epochs,2])\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
        "    time_start_1 = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, locations, directions in train_loader:\n",
        "            inputs, locations, directions = inputs.to(device), locations.to(device), directions.to(device)\n",
        "            directions = directions.float()  # Ensure directions is a float tensor\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            #print(inputs.dtype,inputs.shape)\n",
        "            # print(outputs[0])  # Debug: Check output shape\n",
        "            # print(directions[0])  # Debug: Check target shape\n",
        "            loss = criterion(outputs, directions)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, locations, directions in val_loader:\n",
        "                inputs, locations, directions = inputs.to(device), locations.to(device), directions.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, directions)\n",
        "                val_loss += loss.item()\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        output[epoch][0]=epoch+1\n",
        "        output[epoch][1] = avg_val_loss\n",
        "        if (epoch)%40 == 39:\n",
        "          print(f'Epoch {epoch+1}, Val Loss: {avg_val_loss}, Time cost:{time.time()-time_start_1}s, Time remain: {(time.time()-time_start_1)/(epoch+1)*(num_epochs-epoch)}')\n",
        "    pd.DataFrame(output).to_csv(\"./file_direction_4.csv\")\n",
        "\n",
        "def train_model_location(model, train_loader, val_loader, num_epochs=100):\n",
        "    output = np.zeros([num_epochs,2])\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
        "    time_start_1 = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, locations, directions in train_loader:\n",
        "            inputs, locations, directions = inputs.to(device), locations.to(device), directions.to(device)\n",
        "            locations = locations.float()  # Ensure directions is a float tensor\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            #print(inputs.dtype,inputs.shape)\n",
        "            # print(outputs[0])  # Debug: Check output shape\n",
        "            # print(directions[0])  # Debug: Check target shape\n",
        "            loss = criterion(outputs, locations)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, locations, directions in val_loader:\n",
        "                inputs, locations, directions = inputs.to(device), locations.to(device), directions.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, locations)\n",
        "                val_loss += loss.item()\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        output[epoch][0]=epoch+1\n",
        "        output[epoch][1] = avg_val_loss\n",
        "        if (epoch)%40 == 39:\n",
        "            print(f'Epoch {epoch+1}, Val Loss: {avg_val_loss}, Time cost:{time.time()-time_start_1}s, Time remain: {(time.time()-time_start_1)/(epoch+1)*(num_epochs-epoch)}')\n",
        "    pd.DataFrame(output).to_csv(\"./file_location_4.csv\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    CHANGE_RATE=0.4\n",
        "    SAMPLE = 6000\n",
        "    num_samples = 5000\n",
        "    STEP=9\n",
        "    device = torch.device(\"cuda\" )\n",
        "    F_FEA = get_FEA_matrices(\"1.30_Fx_circ.xlsx\", \\\n",
        "                                \"1.30_Fy_circ.xlsx\", \\\n",
        "                                \"1.30_Fz_circ.xlsx\")\n",
        "    F_normalized_matrix = Normalize_F(F_FEA)\n",
        "    data = data_make(F_normalized_matrix)\n",
        "    dataset = CustomDataset(data)\n",
        "    direction_model = nn.Sequential(LSTMModel(11, 170, 108,2),nn.ReLU(),nn.Dropout(0.2),nn.Linear(108,108),nn.ReLU(),nn.Linear(108,36),nn.Dropout(0.2),nn.ReLU(),nn.Linear(36,3)).to(device)\n",
        "    location_model = nn.Sequential(LSTMModel(11, 170, 108,2),nn.ReLU(),nn.Dropout(0.2),nn.Linear(108,108),nn.ReLU(),nn.Linear(108,36),nn.Dropout(0.2),nn.ReLU(),nn.Linear(36,3)).to(device)\n",
        "    direction_model.load_state_dict(torch.load('direction_model_12i.pth'))\n",
        "    torch.save(direction_model.state_dict(), './direction_model_13i.pth')\n",
        "    torch.save(location_model.state_dict(), './location_model_13i.pth')\n",
        "\n",
        "\n",
        "    # Randomly select indices without replacement\n",
        "    selected_indices = np.random.choice(data.shape[0], num_samples, replace=False)\n",
        "    selected_data = data[selected_indices]\n",
        "    # Find the indices that were not selected\n",
        "    remaining_indices = np.setdiff1d(np.arange(data.shape[0]), selected_indices)\n",
        "\n",
        "    # Use the remaining indices to get the rest of the array\n",
        "    remaining_data = data[remaining_indices]\n",
        "    # Splitting the dataset into training and validation\n",
        "    #train_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "    train_dataset = CustomDataset(selected_data)\n",
        "    val_dataset = CustomDataset(remaining_data)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    # Training the direction model\n",
        "    #train_model_direction(direction_model, train_loader, val_loader, num_epochs=10000)\n",
        "    #torch.save(direction_model.state_dict(), './direction_model_12.pth')\n",
        "    train_model_location(location_model, train_loader, val_loader, num_epochs=10000)\n",
        "    torch.save(location_model.state_dict(), './location_model_12.pth')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNODbc02PXse3XvzMIClRZ2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}